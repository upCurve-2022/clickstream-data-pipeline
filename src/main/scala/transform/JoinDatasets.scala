package transform

import constants.ApplicationConstants._
import org.apache.spark.sql.DataFrame
import org.apache.spark.sql.functions.{lit, to_date}
import utils.ApplicationUtils.commonChecks
import java.sql.Timestamp
import java.time.LocalDateTime
import java.time.format.DateTimeFormatter

object JoinDatasets {
  def joinDataFrame(df1: DataFrame, df2: DataFrame, joinKey: Seq[String], joinType: String): DataFrame = {
    commonChecks(df1, joinKey)
    commonChecks(df2, joinKey)

    val joinedDataFrame: DataFrame = df1.join(df2, joinKey, joinType)
    joinedDataFrame
  }

  def transformDataFrame(df: DataFrame): DataFrame = {
    val currentTime = Timestamp.valueOf(DateTimeFormatter.ofPattern(OUTPUT_TIME_STAMP_FORMAT).format(LocalDateTime.now()))
    val newDfJoin = df.withColumn(EVENT_DATE, to_date(df.col(TIME_STAMP_COL), DATE_FORMAT)).withColumn(RECORD_LOAD_TIME, lit(currentTime))
    newDfJoin
  }
}

